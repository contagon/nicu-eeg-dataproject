{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easton Potokar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import mne                               #package to handle EEG data files\n",
    "import os, seaborn, re\n",
    "from scipy import io                     #for loading matlab file\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "plt.rcParams[\"figure.figsize\"] = [12,5]\n",
    "plt.rcParams[\"figure.dpi\"] = 200\n",
    "\n",
    "fs = 256                                 #sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    return df.read_pickle(filename, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Neonatal seizures are a common occurrence and require immediate care. Detection is only possible through continuous electroencephalogram (EEG) monitoring. Unfortunately, this places a heavy burden on NICUs (Newborn Intensive Care Units) due to the expertise needed to interpret EEGs that is generally not available in a NICU. Alternative options include a simplified easy-to-read trend of the EEG output known as an amplitude integrated EEG (aEEG). While it has its strengths, drawbacks include short duration and low amplitude of seizures, causing them to be missed entirely. \n",
    "\n",
    "Continuous multichannel EEG is the gold standard for detecting seizures but expert interpretation is not readily available to NICUs. Alternatives include providing experts remote access to the EEG, but this still requires 24 hour surveillance, also a heavy load.\n",
    "\n",
    "The dataset that will be used is available through a public repository containing EEG recordings of 79 term neonates admitted to the NICU, with an meidan duration of 74 minutes [1]. Each EEG includes 10 channels of data, each recorded at 256Hz, thus containing frequencies up to 128HZ. These recordings were examined by three experts with their labelings of either a seizure being present or not being present included at minute intervals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "## Data Scraping\n",
    "\n",
    "The data can be found at https://zenodo.org/record/2547147, and is best downloaded using the pip package `zenodo-get`. Running `pip install zenodo-get` followed by `zenodo_get.py 10.5281/zenodo.2547147` downloads all data and checks the md5sums to ensure everything downloaded properly. Since this process was simple enough, no additional scraping methods were needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "### Cleaning Clinical Information\n",
    "\n",
    "The data is stored in a mixture of `.csv` and `.edf` files. The `.edf` files are the standard for EEG data and can be read using the python package `mne`. First, we load the csv files and clean the data found in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in clinical data\n",
    "ci = pd.read_csv(\"data-og/clinical_information.csv\", index_col=\"ID\", usecols=[\"EEG file\", \"ID\", \"Gender\", \"GA (weeks)\", \"BW (g)\"])\n",
    "\n",
    "#replace weight string values with intervals\n",
    "replaceBW = {\"less than 2500g\": pd.Interval(0, 2500),\n",
    "              \"2500 to 3000g\": pd.Interval(2500, 3000),\n",
    "              \"3000 to 3500g\": pd.Interval(3000, 3500),\n",
    "              \"3500 to 4000g\": pd.Interval(3500, 4000),\n",
    "              \"greater than 4000g\": pd.Interval(4000, 4500),\n",
    "              }\n",
    "ci.replace(replaceBW, inplace=True)\n",
    "\n",
    "#replace gestational age string values with intervals\n",
    "def interval(weeks):\n",
    "    if not isinstance(weeks, str) and np.isnan(weeks):\n",
    "        return weeks\n",
    "    values = re.compile(r\"(\\d{2})\").findall(weeks)\n",
    "    return pd.Interval(int(values[0]), int(values[1]))\n",
    "ci['GA (weeks)'] = ci['GA (weeks)'].apply(interval)\n",
    "\n",
    "#load in all experts analysis from .mat file. Note we save as a numpy array b/c each child has a different length of recording\n",
    "annot = io.loadmat('data-og/annotations_2017.mat')['annotat_new']\n",
    "ci['expertA'] = [annot[0,i-1][0,:] for i in ci.index]\n",
    "ci['expertB'] = [annot[0,i-1][1,:] for i in ci.index]\n",
    "ci['expertC'] = [annot[0,i-1][2,:] for i in ci.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning EEG Data\n",
    "\n",
    "Next, we use `mne` to read all data into a pandas DataFrame. The corresponding info, like the expert's analysis; baby information; etc, is saved as metadata on each seperate dataFrame and then saved as a pickle file for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#iterate through all of files\n",
    "for i in ci.index:\n",
    "    #read in all of the raw data\n",
    "    raw = mne.io.read_raw_edf(\"data-og/{}.edf\".format(ci[\"EEG file\"][i]))\n",
    "    channels = raw.ch_names\n",
    "    signals = raw[channels][0]\n",
    "    time = raw[0,:][1]\n",
    "\n",
    "    #save into pandas DataFrame\n",
    "    df = pd.DataFrame(signals.T, columns=channels, index=time)\n",
    "    df.ID = i\n",
    "    df.gender = ci['Gender'][i]\n",
    "    df.bw = ci['BW (g)'][i]\n",
    "    df.ga = ci['GA (weeks)'][i]\n",
    "    df._metadata = ['gender', 'bw', 'ga', 'ID']\n",
    "    \n",
    "    #check to make sure all experts analyzed correctly sized data\n",
    "    if len(ci['expertA'][i]) != len(df.index) / 256:\n",
    "        print(len(ci['expertA'][i]), len(df.index) / 256)\n",
    "        raise ValueError(\"EEG {} has mismatched expert A and time stamps\")\n",
    "    if len(ci['expertB'][i]) != len(df.index) / 256:\n",
    "        print(len(ci['expertB'][i]), len(df.index) / 256)\n",
    "        raise ValueError(\"EEG {} has mismatched expert B and time stamps\")\n",
    "    if len(ci['expertC'][i]) != len(df.index) / 256:\n",
    "        print(len(ci['expertC'][i]), len(df.index) / 256)\n",
    "        raise ValueError(\"EEG {} has mismatched expert C and time stamps\")\n",
    "        \n",
    "    #save to gzipped pickle file and update location in ci\n",
    "    print(\"Saving {} to pklz...\".format(ci[\"EEG file\"][i]))\n",
    "    df.to_pickle('data/{}.pklz'.format(ci[\"EEG file\"][i]), compression=\"gzip\", protocol=-1)\n",
    "    ci[\"EEG file\"][i] = \"data/{}.pklz\".format(ci[\"EEG file\"][i])\n",
    "    \n",
    "ci.to_pickle('data/ci_cleaned.pklz', compression=\"gzip\", protocol=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Data Problems\n",
    "\n",
    "I believe the source of the data to be quite reliable. The data was recorded from a hospital in Finland by a third party, which removes any sort of bias or data picking. The group who posted it was also looking to implement different ML algorithmns to detect seizures and appeared to be at least moderately successful using an SVM. As long as the group didn't cherry-pick data for their model, which seems unlikely since that would be unethical and it's been published, the data should be sufficiently reliable.\n",
    "\n",
    "Upon examining the data, I found that the length of recordings didn't match up with the length of some of the analyses by \"Expert A\", which obviously raises a lot of alarms. Upon further inspection, there appears to be something wrong with the `.csv` file containing Expert A's annotations. Fortunately, a `.mat` file was also included in the dataset and all the lengths match up for each expert and the EEG data. Beyond that, all data appears to have valid information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci['expertA_avg'] = [np.sum(ci['expertA'][i]) / len(ci['expertA'][i]) for i in ci.index]\n",
    "ci['expertB_avg'] = [np.sum(ci['expertB'][i]) / len(ci['expertB'][i]) for i in ci.index]\n",
    "ci['expertC_avg'] = [np.sum(ci['expertC'][i]) / len(ci['expertC'][i]) for i in ci.index]\n",
    "ci['minutes'] = [len(ci['expertA'][i])/60 for i in ci.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "title": "Analyzing EEG Recordings of Neonatals"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
